{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefanosdl/Neural_Networks_and_clustering_of_images/blob/d.cluster/src/a.Autoencoder/Code_for_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxI19ruBE9Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57fa8e6-2c4e-440b-ccba-8277a9f76aa2"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "# print(\"Tensorflow version \" + tf.__version__)\r\n",
        "\r\n",
        "try:\r\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\r\n",
        "except ValueError:\r\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.120.53.146:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.120.53.146:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7T6kt4VFUM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b150840e-e0c5-46ed-c32d-db3b9066930f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCFfb2G1FVzM"
      },
      "source": [
        "#Datasets\r\n",
        "path = \"/content/drive/My Drive/Project_Ergasia3/Datasets/\"\r\n",
        "dataset = path + \"train-images.idx3-ubyte\"\r\n",
        "queryset = path + \"t10k-images.idx3-ubyte\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuDMF8LlVRQs"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHTqsUFhVlSb"
      },
      "source": [
        "def reader(dataset):\n",
        "    # create a dictionary of lists to store all images\n",
        "    all_images = {}\n",
        "    all_images[0] = []\n",
        "    with open(dataset, \"rb\") as f:\n",
        "        counter = 0\n",
        "        # read metadata\n",
        "        byte = f.read(4)\n",
        "        while byte:\n",
        "            if counter == 0:\n",
        "                magic_number = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 1:\n",
        "                number_of_images = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 2:\n",
        "                rows = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 3:\n",
        "                cols = int.from_bytes(byte, \"big\")\n",
        "                break\n",
        "            counter += 1\n",
        "            byte = f.read(4)\n",
        "        # start reading the images \n",
        "        byte_counter = 0\n",
        "        image_counter = 0\n",
        "        dimensions = rows * cols\n",
        "        print (magic_number, \" \", number_of_images,\" \", rows,\" \", cols, \" \", dimensions)\n",
        "        # read images, byte byte\n",
        "        byte = f.read(1)\n",
        "        while byte:\n",
        "            # store byte in the \n",
        "            all_images[image_counter].append(int.from_bytes(byte, \"big\"))\n",
        "            byte_counter += 1\n",
        "            if (byte_counter == dimensions):\n",
        "                # next image\n",
        "                image_counter += 1\n",
        "                byte_counter = 0\n",
        "                # initialize the list for this image\n",
        "                all_images[image_counter] = []\n",
        "            byte = f.read(1)\n",
        "    # finished with reading of file\n",
        "    # remove last item number_of_images index that is anyway an empty list\n",
        "    all_images.popitem()\n",
        "    print (\"finished reading from file\")\n",
        "    # return a tuple of number of images, dimensions and all_images dict\n",
        "    return all_images\n",
        "\n",
        "def reader_labels(dataset):\n",
        "    # create a dictionary of lists to store all images\n",
        "    all_labels = []\n",
        "    with open(dataset, \"rb\") as f:\n",
        "        counter = 0\n",
        "        # read metadata\n",
        "        byte = f.read(4)\n",
        "        while byte:\n",
        "            if counter == 0:\n",
        "                magic_number = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 1:\n",
        "                number_of_items = int.from_bytes(byte, \"big\")\n",
        "                break\n",
        "            counter += 1\n",
        "            byte = f.read(4)\n",
        "\n",
        "\t\t# start reading the labels \n",
        "        byte = f.read(1)\n",
        "        while byte:\n",
        "\t\t\t# store byte in the \n",
        "            all_labels.append(int.from_bytes(byte, \"big\"))\n",
        "            byte = f.read(1)\n",
        "            # finished with reading of file\n",
        "    return all_labels\n",
        "\n",
        "def read_all_files(training_set, training_labels, test_set, test_labels):\n",
        "\ttrain_images = reader(training_set)\n",
        "\ttrain_labels = reader_labels(training_labels) \n",
        "\ttest_images = reader(test_set)\n",
        "\ttest_labels = reader_labels(test_labels)\n",
        "\t# labels are lists of 10000 items\n",
        "\treturn (train_images, train_labels, test_images, test_labels)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT4I1doBVtkw"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "# from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9UOdyGMWgMD"
      },
      "source": [
        "def convolutionalAutoencoder():\r\n",
        "    keras.backend.clear_session()\r\n",
        "    print(\"[INFO] building autoencoder...\")\r\n",
        "    model = tf.keras.models.Sequential()\r\n",
        "    model.add(layers.Input(shape=(28, 28, 1)))\r\n",
        "\r\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\r\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\r\n",
        "    model.add(layers.BatchNormalization())\r\n",
        "    model.add(layers.MaxPooling2D((2,2), padding='same'))\r\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same', strides=3))\r\n",
        "\r\n",
        "    model.add(layers.Flatten())\r\n",
        "    model.add(layers.Dense(10, activation='relu'))\r\n",
        "    model.add(layers.Dropout(0.4))\r\n",
        "    model.add(layers.Dense(1152, activation='relu'))\r\n",
        "\r\n",
        "    model.add(layers.Reshape((2, 2, 288)))\r\n",
        "\r\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'))\r\n",
        "    model.add(layers.Conv2DTranspose(32, kernel_size=4, strides=1, activation='relu'))\r\n",
        "    model.add(layers.BatchNormalization())\r\n",
        "    model.add(layers.UpSampling2D((2, 2)))\r\n",
        "    model.add(layers.Conv2DTranspose(1, kernel_size=3, strides=2, activation='sigmoid', padding='same'))\r\n",
        "\r\n",
        "    return model\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjiB8kXbWwrU"
      },
      "source": [
        "# training \r\n",
        "def training(autoencoder, all_images, epochs=50, batch_size=128):\r\n",
        "\tprint(\"[INFO] training started...\")\r\n",
        "\tdf = pd.DataFrame.from_dict(all_images, orient='index')\r\n",
        "\t# now in df we have a dataframe with size: dimensions x number_of_images with all of our images\r\n",
        "\topt = keras.optimizers.Adam(lr=1e-3)\r\n",
        "\t# loss = 'binary_crossentropy'\r\n",
        "\tautoencoder.compile(loss=\"mse\", optimizer=opt, metrics = ['accuracy'])\r\n",
        "\r\n",
        "\t# To train it we will need the data\r\n",
        "\ttrain, test = train_test_split(df, test_size=0.33, random_state=42)\r\n",
        "\r\n",
        "\t# train = train.astype('float32') / 255.\r\n",
        "\t# test = test.astype('float32') / 255.\r\n",
        "\r\n",
        "\ttrain = train.to_numpy()\r\n",
        "\ttest = test.to_numpy()\r\n",
        "\r\n",
        "\ttrain = np.reshape(train, (len(train), 28, 28, 1))\r\n",
        "\ttest = np.reshape(test, (len(test), 28, 28, 1))\r\n",
        "\r\n",
        "\thistory = autoencoder.fit(train, train,\r\n",
        "\t\t\t\t\tepochs=epochs,\r\n",
        "\t\t\t\t\tbatch_size=batch_size,\r\n",
        "\t\t\t\t\tshuffle=True,\r\n",
        "\t\t\t\t\tvalidation_data=(test, test),\r\n",
        "\t\t\t\t\tcallbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)])\r\n",
        "\r\n",
        "\treturn history"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djk3y5KNW0BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6fae0ab-c028-467b-9ef8-02cd93dc3516"
      },
      "source": [
        "# run this\r\n",
        "autoencoder = convolutionalAutoencoder()\r\n",
        "autoencoder.summary()\r\n",
        "len(autoencoder.layers)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] building autoencoder...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1152)              12672     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 2, 2, 288)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 4, 4, 64)          165952    \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 7, 7, 32)          32800     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         289       \n",
            "=================================================================\n",
            "Total params: 309,899\n",
            "Trainable params: 309,707\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIrUWvhGoWU6"
      },
      "source": [
        "all_images = reader(dataset)\n",
        "query_images = reader(queryset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBh5C2xDobQe",
        "outputId": "740774c6-6ef6-4c49-9567-15960b8ee3ba"
      },
      "source": [
        "history = training(autoencoder, all_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training started...\n",
            "Epoch 1/50\n",
            "315/315 [==============================] - 15s 45ms/step - loss: 7210.2228 - accuracy: 0.4705 - val_loss: 7209.9829 - val_accuracy: 0.3956\n",
            "Epoch 2/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7229.9222 - accuracy: 0.3896 - val_loss: 7204.6431 - val_accuracy: 0.4314\n",
            "Epoch 3/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7232.7802 - accuracy: 0.3945 - val_loss: 7204.0112 - val_accuracy: 0.4681\n",
            "Epoch 4/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7233.4679 - accuracy: 0.4241 - val_loss: 7203.8960 - val_accuracy: 0.4716\n",
            "Epoch 5/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7227.0933 - accuracy: 0.4499 - val_loss: 7203.8755 - val_accuracy: 0.4764\n",
            "Epoch 6/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7211.5618 - accuracy: 0.4736 - val_loss: 7203.8867 - val_accuracy: 0.4786\n",
            "Epoch 7/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7232.8844 - accuracy: 0.4850 - val_loss: 7203.8657 - val_accuracy: 0.4896\n",
            "Epoch 8/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7211.3083 - accuracy: 0.4954 - val_loss: 7203.8618 - val_accuracy: 0.4856\n",
            "Epoch 9/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7214.1180 - accuracy: 0.5029 - val_loss: 7203.8555 - val_accuracy: 0.4971\n",
            "Epoch 10/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7233.4920 - accuracy: 0.5128 - val_loss: 7203.8472 - val_accuracy: 0.4938\n",
            "Epoch 11/50\n",
            "315/315 [==============================] - 14s 43ms/step - loss: 7220.8109 - accuracy: 0.5164 - val_loss: 7203.8643 - val_accuracy: 0.4991\n",
            "Epoch 12/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7231.8569 - accuracy: 0.5210 - val_loss: 7203.8745 - val_accuracy: 0.4858\n",
            "Epoch 13/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7231.1910 - accuracy: 0.5240 - val_loss: 7203.8530 - val_accuracy: 0.4979\n",
            "Epoch 14/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7233.1730 - accuracy: 0.5282 - val_loss: 7203.8682 - val_accuracy: 0.4909\n",
            "Epoch 15/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7218.7145 - accuracy: 0.5328 - val_loss: 7203.8652 - val_accuracy: 0.5120\n",
            "Epoch 16/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7212.8939 - accuracy: 0.5361 - val_loss: 7203.8618 - val_accuracy: 0.4987\n",
            "Epoch 17/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7219.0774 - accuracy: 0.5228 - val_loss: 7203.8350 - val_accuracy: 0.5175\n",
            "Epoch 18/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7209.5920 - accuracy: 0.5402 - val_loss: 7203.8247 - val_accuracy: 0.5209\n",
            "Epoch 19/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7218.0752 - accuracy: 0.5447 - val_loss: 7203.8423 - val_accuracy: 0.5099\n",
            "Epoch 20/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7233.5924 - accuracy: 0.5437 - val_loss: 7203.8633 - val_accuracy: 0.5248\n",
            "Epoch 21/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7209.4698 - accuracy: 0.5460 - val_loss: 7203.8188 - val_accuracy: 0.5290\n",
            "Epoch 22/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7228.5845 - accuracy: 0.5484 - val_loss: 7203.8867 - val_accuracy: 0.5240\n",
            "Epoch 23/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7238.0038 - accuracy: 0.5420 - val_loss: 7203.8359 - val_accuracy: 0.5317\n",
            "Epoch 24/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7234.8683 - accuracy: 0.5464 - val_loss: 7203.8730 - val_accuracy: 0.5290\n",
            "Epoch 25/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7215.3862 - accuracy: 0.5513 - val_loss: 7203.8296 - val_accuracy: 0.5262\n",
            "Epoch 26/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7214.4964 - accuracy: 0.5511 - val_loss: 7203.8408 - val_accuracy: 0.5227\n",
            "Epoch 27/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7234.4545 - accuracy: 0.5548 - val_loss: 7203.8115 - val_accuracy: 0.5380\n",
            "Epoch 28/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7233.0875 - accuracy: 0.5509 - val_loss: 7203.8115 - val_accuracy: 0.5361\n",
            "Epoch 29/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7214.3099 - accuracy: 0.5577 - val_loss: 7203.8853 - val_accuracy: 0.5333\n",
            "Epoch 30/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7226.3543 - accuracy: 0.5587 - val_loss: 7203.9380 - val_accuracy: 0.5291\n",
            "Epoch 31/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7220.2931 - accuracy: 0.5598 - val_loss: 7203.8398 - val_accuracy: 0.5372\n",
            "Epoch 32/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7225.5841 - accuracy: 0.5626 - val_loss: 7203.8530 - val_accuracy: 0.5398\n",
            "Epoch 33/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7220.1072 - accuracy: 0.5620 - val_loss: 7203.8198 - val_accuracy: 0.5432\n",
            "Epoch 34/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7207.8105 - accuracy: 0.5637 - val_loss: 7203.8101 - val_accuracy: 0.5537\n",
            "Epoch 35/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7235.1483 - accuracy: 0.5659 - val_loss: 7203.8408 - val_accuracy: 0.5367\n",
            "Epoch 36/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7230.5152 - accuracy: 0.5592 - val_loss: 7203.8184 - val_accuracy: 0.5359\n",
            "Epoch 37/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7249.2207 - accuracy: 0.5634 - val_loss: 7203.8076 - val_accuracy: 0.5449\n",
            "Epoch 38/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7233.0729 - accuracy: 0.5659 - val_loss: 7203.8457 - val_accuracy: 0.5461\n",
            "Epoch 39/50\n",
            "315/315 [==============================] - 11s 36ms/step - loss: 7201.0687 - accuracy: 0.5660 - val_loss: 7203.8198 - val_accuracy: 0.5473\n",
            "Epoch 40/50\n",
            "315/315 [==============================] - 12s 39ms/step - loss: 7231.6236 - accuracy: 0.5660 - val_loss: 7203.8110 - val_accuracy: 0.5414\n",
            "Epoch 41/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7227.0119 - accuracy: 0.5682 - val_loss: 7203.8301 - val_accuracy: 0.5428\n",
            "Epoch 42/50\n",
            "315/315 [==============================] - 12s 37ms/step - loss: 7211.0929 - accuracy: 0.5687 - val_loss: 7203.8276 - val_accuracy: 0.5520\n",
            "Epoch 43/50\n",
            "313/315 [============================>.] - ETA: 0s - loss: 7211.4254 - accuracy: 0.5708"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnXChFmsAy6"
      },
      "source": [
        "# Get the encoder from autoencoder model\r\n",
        "encoder = tf.keras.models.Sequential()\r\n",
        "encoder.add(layers.Input(shape=(28, 28, 1)))\r\n",
        "for i in range(0, len(autoencoder.layers)//2):\r\n",
        "    encoder.add(autoencoder.layers[i])\r\n",
        "\r\n",
        "test = pd.DataFrame.from_dict(query_images, orient='index')\r\n",
        "test = test.to_numpy()\r\n",
        "test = np.reshape(test, (len(test), 28, 28, 1))\r\n",
        "\r\n",
        "train = pd.DataFrame.from_dict(all_images, orient='index')\r\n",
        "train = train.to_numpy()\r\n",
        "train = np.reshape(train, (len(train), 28, 28, 1))\r\n",
        "# Get the images from the Embedded layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NClCFpwwk9kz"
      },
      "source": [
        "query_imgs = encoder.predict(test)\n",
        "dataset_imgs = encoder.predict(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Ymyjnjba9d"
      },
      "source": [
        "normalized_query = []\n",
        "for i in range(len(query_imgs)):\n",
        "    normalized_query.append((25500*(query_imgs[i] - np.min(query_imgs[i]))/np.ptp(query_imgs[i])).astype(int))\n",
        "\n",
        "normalized_dataset = []\n",
        "for i in range(len(dataset_imgs)):\n",
        "    normalized_dataset.append((25500*(dataset_imgs[i] - np.min(dataset_imgs[i]))/np.ptp(dataset_imgs[i])).astype(int))\n",
        "\n",
        "normalized_query = np.asarray(normalized_query)\n",
        "normalized_dataset = np.asarray(normalized_dataset)\n",
        "# print(normalized_query.max())\n",
        "# print(normalized_dataset.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0-rh3qGXZfW"
      },
      "source": [
        "import struct\n",
        "def writeToFile(normalized, path):\n",
        "    # normalized.astype(np.ushort)\n",
        "    # TODO: CHANGE THE PATH\n",
        "    outputfile = open(path, \"wb\")\n",
        "    number_of_images = normalized.shape[0]\n",
        "    dimensions = normalized.shape[1]\n",
        "    # write metadata\n",
        "    # enforce big endian\n",
        "    myfmt = '>i'\n",
        "    # write magic number\n",
        "    bin = struct.pack(myfmt, 2081)\n",
        "    outputfile.write(bin)\n",
        "    # write num of images\n",
        "    bin = struct.pack(myfmt, number_of_images)\n",
        "    outputfile.write(bin)\n",
        "    # write num of rows (1)\n",
        "    bin = struct.pack(myfmt, 1)\n",
        "    outputfile.write(bin)\n",
        "    # write dimensions\n",
        "    bin = struct.pack(myfmt, dimensions)\n",
        "    outputfile.write(bin)\n",
        "    # enforce little endian\n",
        "    myfmt = 'H'*dimensions\n",
        "    myfmt = '<' + myfmt\n",
        "    #  You can use 'H' for unsigned short and <, for little endian to force endinness\n",
        "    for i in range(0, number_of_images):\n",
        "        arr = np.array(normalized[i])\n",
        "        bin = struct.pack(myfmt, *arr)\n",
        "        outputfile.write(bin)\n",
        "\n",
        "    outputfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dum3jYommkdw"
      },
      "source": [
        "writeToFile(normalized_query, \"output_query_file\")\n",
        "writeToFile(normalized_dataset, \"output_dataset_file\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFTccctj-Awb"
      },
      "source": [
        "import os\n",
        "print(os.path.getsize(\"output_query_file\"))\n",
        "print(os.path.getsize(\"output_dataset_file\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei1m5khC_jWK"
      },
      "source": [
        "def reader10(dataset):\n",
        "    # create a dictionary of lists to store all images\n",
        "    all_images = {}\n",
        "    all_images[0] = []\n",
        "    with open(dataset, \"rb\") as f:\n",
        "        counter = 0\n",
        "        # read metadata\n",
        "        byte = f.read(4)\n",
        "        while byte:\n",
        "            if counter == 0:\n",
        "                magic_number = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 1:\n",
        "                number_of_images = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 2:\n",
        "                rows = int.from_bytes(byte, \"big\")\n",
        "            elif counter == 3:\n",
        "                cols = int.from_bytes(byte, \"big\")\n",
        "                break\n",
        "            counter += 1\n",
        "            byte = f.read(4)\n",
        "        # start reading the images \n",
        "        byte_counter = 0\n",
        "        image_counter = 0\n",
        "        dimensions = rows * cols\n",
        "        print (magic_number, \" \", number_of_images,\" \", rows,\" \", cols, \" \", dimensions)\n",
        "        # read images, byte byte\n",
        "        byte = f.read(2)\n",
        "        while byte:\n",
        "            # store byte in the \n",
        "            all_images[image_counter].append(int.from_bytes(byte, \"little\"))\n",
        "            byte_counter += 2\n",
        "            if (byte_counter == 2*dimensions):\n",
        "                # next image\n",
        "                image_counter += 1\n",
        "                byte_counter = 0\n",
        "                # initialize the list for this image\n",
        "                all_images[image_counter] = []\n",
        "            byte = f.read(2)\n",
        "    # finished with reading of file\n",
        "    # remove last item number_of_images index that is anyway an empty list\n",
        "    all_images.popitem()\n",
        "    print (\"finished reading from file\")\n",
        "    # return a tuple of number of images, dimensions and all_images dict\n",
        "    return all_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRJNzLDS_mh8"
      },
      "source": [
        "im = reader10(\"output_dataset_file\")\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}